{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt PRiAD Natalia Biernacka, Anton Libik\n",
    "### Wybrany zbiór danych: Titanic Survival Prediction Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie i wczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import niezbędnych pakietów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\") \n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file_path = os.path.join(path, 'Titanic-Dataset.csv')\n",
    "dane = pd.read_csv(file_path)\n",
    "dane.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza eksploracyjna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Wyznaczamy liczbę obiektów, liczbę atrybutów. Usuwamy kolumny PassengetId, Ticket i Name - nie są one potrzebne dla dalszej analizy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba obiektów\n",
    "print(\"Liczba obiektów:\", dane.shape[0])\n",
    "\n",
    "# liczba atrybutów\n",
    "print(\"Liczba atrybutow:\", dane.shape[1])\n",
    "\n",
    "# usuwanie kolumny PassengerId i Name\n",
    "dane.drop(columns=['PassengerId'], inplace=True)\n",
    "dane.drop(columns=['Name'], inplace=True)\n",
    "dane.drop(columns=['Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Liczba obiektów, reprezentujących pasażerów, którzy przeżyli (atrybut survived ma 1) i którzy nie (survived = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivedDF = dane[dane.Survived == 1]\n",
    "\n",
    "notSurvivedDF = dane[dane.Survived == 0]\n",
    "\n",
    "print(\"Liczba pasażerów, którzy przeżyli: \", survivedDF.shape[0])\n",
    "print(\"Liczba pasażerów, którzy nie przeżyli: \", notSurvivedDF.shape[0])\n",
    "\n",
    "procent = survivedDF.shape[0] / dane.shape[0] * 100\n",
    "print(\"Ile procent przeżyło: \", round(procent, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Liczba brakujących danych w poszczególnych kolumnach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Usuwamy kolumnę \"Cabin\", ponieważ zawiera dużą liczbę brakujących danyh i będzie przeszkadać analizie. Zamiast brakujących danych w kolumnie \"Age\" wstawiamy dane średniego wieku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy kolumnę Cabin\n",
    "dane.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# wstawiamy średni wiek zamiast brakujących danych w kolumnie Age\n",
    "dane['Age'] = dane['Age'].fillna(dane['Age'].median())\n",
    "\n",
    "# sprawdzamy liczbę brakujących danych \n",
    "dane.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Usuwamy pozostałe brakujące dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = dane.dropna()\n",
    "\n",
    "dane.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Zbiór został przygotowany do analizy ekploracyjnej, ostateczna liczba obiektów i atrybutów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba obiektów\n",
    "print(\"Liczba obiektów:\", dane.shape[0])\n",
    "\n",
    "# liczba atrybutów\n",
    "print(\"Liczba atrybutow:\", dane.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analiza zmienności atrybutów bez odniesienia do przeżycia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dane.describe())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(4,2,1)\n",
    "sns.violinplot(data=dane['Pclass'])\n",
    "plt.subplot(4,2,2)\n",
    "sns.violinplot(data=dane['Age'])\n",
    "plt.subplot(4,2,3)\n",
    "sns.violinplot(data=dane['SibSp'])\n",
    "plt.subplot(4,2,4)\n",
    "sns.violinplot(data=dane['Parch'])\n",
    "plt.subplot(4,2,5)\n",
    "sns.violinplot(data=dane['Fare'])\n",
    "plt.subplot(4,2,6)\n",
    "sns.histplot(data=dane, x=\"Sex\", hue=\"Sex\")\n",
    "plt.subplot(4,2,7)\n",
    "sns.histplot(data=dane, x=\"Embarked\", hue=\"Embarked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analiza zmienności atrybutów w zależności od przeżycia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dane[dane['Survived'] == 0].describe())\n",
    "print(dane[dane['Survived'] == 1].describe())\n",
    "plt.figure(figsize= (20,20))\n",
    "plt.subplot(4, 2, 1)\n",
    "sns.violinplot(x = 'Survived', y = 'Age', data=dane, legend=False, hue = 'Survived')\n",
    "plt.subplot(4, 2, 2)\n",
    "sns.violinplot(x = 'Survived', y = 'SibSp', data=dane, legend=False, hue = 'Survived')\n",
    "plt.subplot(4, 2, 3)\n",
    "sns.violinplot(x = 'Survived', y = 'Parch', data=dane, legend=False, hue = 'Survived')\n",
    "plt.subplot(4, 2, 4)\n",
    "sns.violinplot(x = 'Survived', y = 'Fare', data=dane, legend=False, hue = 'Survived')\n",
    "plt.figure(figsize= (5,5))\n",
    "plt.xticks([0, 1])\n",
    "sns.countplot(data=dane, x=\"Survived\", hue=\"Sex\")\n",
    "plt.figure(figsize= (5,5))\n",
    "plt.xticks([0, 1])\n",
    "sns.countplot(data=dane, x=\"Survived\", hue=\"Embarked\")\n",
    "plt.figure(figsize= (5,5))\n",
    "plt.xticks([0, 1])\n",
    "sns.countplot(data=dane, x=\"Survived\", hue=\"Pclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski\n",
    "* Rozkład wartości atrybutów Age, SibSp, Parch i Fare dla pasażerów, którzy przeżyli i nie przeżyli jest podobny. Możemy zaobserwować, że w przypadku grupy dzieci (wiek ok. 10 lat) oraz osób, których cena biletu wynosiła powyżej 100, większość przezyła\n",
    "* Przeżywalność jest w dużym stopniu zależna od płci. Większość kobiet przeżyła, zaś znaczna większość mężczyzn zginęła.\n",
    "* Port, z którego pasażer wszedł na pokład nie ma większego znaczenia.\n",
    "* Na przeżywalność silnie wpłynęła klasa, w której podróżował pasażer - większość osób z klasy 1 przeżyła zaś z klasy 3 zdecydowana większość zginęła"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wykres punktowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dane, kind = 'scatter', hue = \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Korelacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor = dane.loc[:, np.logical_and(dane.columns != \"Sex\", dane.columns != \"Embarked\")].corr()\n",
    "print(kor)\n",
    "plt.figure(figsize=(10,8), dpi =100)\n",
    "sns.heatmap(kor, annot=kor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "* najsilniej skolerowane są cena biletu (Fare) oraz klasa (Pclass) - cena biletu wyższa dla klasy 1, nieco niższa dla klasy 2 i najniższa dla klasy 3\n",
    "* z przeżywalnością (survived) najsilniej skolerowana jest klasa, co potwierdza wnioski z analizy zmienności atrybutów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie nadzorowane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wygodniej było prowadzić uczenie nadzorowane, zamieniamy wartości column Sex i Embarked na wartości liczbowe według następnego schematu:  \n",
    "Sex - (male => 1, female => 0),  \n",
    "Emarked - (C => 1, S => 2, Q => 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dane.head())\n",
    "\n",
    "dane['Sex'] = np.where(dane['Sex'] == 'male', 1, 0)\n",
    "dane['Embarked'] = np.where(dane['Embarked'] == 'C', 1, dane['Embarked'])\n",
    "dane['Embarked'] = np.where(dane['Embarked'] == 'S', 2, dane['Embarked'])\n",
    "dane['Embarked'] = np.where(dane['Embarked'] == 'Q', 3, dane['Embarked'])\n",
    "\n",
    "print(dane.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres punktowy, który pozwoli na określenie, które atrybuty są bardziej, a które mniej istotne w kontekscie uczenia nadzorowanego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dane, kind = 'scatter', hue = \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z wykresu punktowego możemy wyciągnąć wniosek, że najbardziej istotnymi dla nas będą pary atrybutów: Sex i Pclass, Pclass i Embarked, Sex i Age, Fare i Sex, Sex i Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import niezbędnych pakietów oraz funkcje dzielenia zbioru na ucząct i testowy, weryfikacji i wyświtlenia granic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "def podziel(df,proporcja):\n",
    "    # dzieli macierz (ramkę) danych na zbiór uczacy i testowy\n",
    "    # df - ramka danych; proporcja - proporcja podzialu (0-1)\n",
    "    # zwraca słownik z kluczami:\n",
    "    # opis_ucz/opis_test - macierz atrybutów opisujących zbioru uczącego/testowego\n",
    "    # dec_ucz/dec_test - wektor wartosci atrybutu decyzyjnego zbioru uczącego/testowego\n",
    "    # uwaga: atrybut opisujący jest zawsze na końcu (ostatnia kolumna ramki)\n",
    "    opis_ucz, opis_test, dec_ucz, dec_test = train_test_split(df.iloc[:,0:-1], df.iloc[:,-1].astype('category').cat.codes, test_size=proporcja)#, random_state=0)\n",
    "    return {\"opis_ucz\":opis_ucz, \"opis_test\":opis_test, \"dec_ucz\":dec_ucz, \"dec_test\":dec_test}\n",
    "\n",
    "\n",
    "def weryfikuj(model,dane,atryb):\n",
    "    # wyswietla wynik weryfikacji klasyfikatora w postaci macierzy pomyłek\n",
    "    # dla zbioru uczącego i testowego\n",
    "    # model - model klasyfikatora\n",
    "    # dane - dane (słownik zwracany przez funkcje podziel)\n",
    "    # atryb - lista atrybutów uwzględnianych w weryfikacji\n",
    "    model.fit(dane[\"opis_ucz\"].iloc[:,atryb], dane[\"dec_ucz\"])\n",
    "    wynik_ucz = model.predict(dane[\"opis_ucz\"].iloc[:,atryb])\n",
    "    wynik_test = model.predict(dane[\"opis_test\"].iloc[:,atryb])\n",
    "    mp = confusion_matrix(dane[\"dec_ucz\"],wynik_ucz)\n",
    "    print(\"macierz pomyłek - zbiór uczący, dokładność:\",np.sum(np.diag(mp))/np.sum(mp))\n",
    "    #print(model.score(dane['opis_ucz'],dane['dec_ucz']))\n",
    "    print(mp)\n",
    "    mp = confusion_matrix(dane[\"dec_test\"],wynik_test)\n",
    "    print(\"macierz pomyłek - zbiór testowy, dokładność:\",np.sum(np.diag(mp))/np.sum(mp))\n",
    "    #print(model.score(dane['opis_test'],dane['dec_test']))\n",
    "    print(mp) \n",
    "\n",
    "def granice(model,dane,atr_x, atr_y,tytul,kontur = 1):\n",
    "    # wyświetla granice decyzyjne\n",
    "    # model - model klasyfikatora\n",
    "    # dane - dane (słownik zwracany przez funkcje podziel)\n",
    "    # atr_x/atr_y - artybut wyswietlany na osi x/y\n",
    "    # tytul - wyświetlany tytuł wykresu\n",
    "    # kontur - par. opcjonalny (=0 -> brak konturu)\n",
    "    if (kontur == 1):    \n",
    "        model.fit(np.array(dane[\"opis_ucz\"].iloc[:,[atr_x,atr_y]]), np.array(dane[\"dec_ucz\"]))\n",
    "        x_min = min(dane[\"opis_ucz\"].iloc[:, atr_x].min(),dane[\"opis_test\"].iloc[:, atr_x].min())\n",
    "        x_max = max(dane[\"opis_ucz\"].iloc[:, atr_x].max(),dane[\"opis_test\"].iloc[:, atr_x].max())\n",
    "        y_min = min(dane[\"opis_ucz\"].iloc[:, atr_y].min(),dane[\"opis_test\"].iloc[:, atr_y].min())\n",
    "        y_max = max(dane[\"opis_ucz\"].iloc[:, atr_y].max(),dane[\"opis_test\"].iloc[:, atr_y].max())\n",
    "        rozst_x = x_max - x_min\n",
    "        rozst_y = y_max - y_min\n",
    "        x_min = x_min - 0.1*rozst_x\n",
    "        x_max = x_max + 0.1*rozst_x\n",
    "        y_min = y_min - 0.1*rozst_y\n",
    "        y_max = y_max + 0.1*rozst_y       \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max-x_min)/150),\n",
    "                     np.arange(y_min, y_max, (y_max-y_min)/150))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "    plt.figure(dpi = 100)\n",
    "    plt.title(tytul)\n",
    "    if (kontur == 1):\n",
    "        plt.contourf(xx, yy, Z, levels = 4, alpha=0.2)\n",
    "    plt.scatter(dane[\"opis_ucz\"].iloc[:, atr_x], dane[\"opis_ucz\"].iloc[:, atr_y], c=dane[\"dec_ucz\"], marker = '.')\n",
    "    plt.scatter(dane[\"opis_test\"].iloc[:, atr_x], dane[\"opis_test\"].iloc[:, atr_y], c=dane[\"dec_test\"], marker = 'x')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybrane pary atrybutów dla uczenia nadzorowanego i podział zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrybuty = [ ['Sex', 'Pclass'], ['Pclass', 'Embarked'], ['Sex', 'Age'], ['Fare', 'Sex'], ['Sex', 'Embarked']]\n",
    "\n",
    "# podział zbioru danych\n",
    "dane_podzielone = podziel(dane,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda k-najbliższych sąsiadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wybór liczby sąsiadów\n",
    "k = 1\n",
    "\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "for aktualne_atrybuty in atrybuty:\n",
    "    atrybut_1  = aktualne_atrybuty[0]\n",
    "    atrybut_2 = aktualne_atrybuty[1]\n",
    "\n",
    "    atrybut_1_index = dane.columns.get_loc(atrybut_1) - 1\n",
    "    atrybut_2_index = dane.columns.get_loc(atrybut_2) - 1\n",
    "\n",
    "    # zdefiniowanie modelu klasyfikatora\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # weryfikacja\n",
    "    weryfikuj(model,dane_podzielone,[atrybut_1_index,atrybut_2_index])\n",
    "\n",
    "    granice(model, dane_podzielone, atrybut_1_index, atrybut_2_index, \"n_neighbours dla x = \" + atrybut_1 + \", y = \" + atrybut_2 + \", k = \" + str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naiwny klasyfikator Bayesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "for aktualne_atrybuty in atrybuty:\n",
    "    atrybut_1  = aktualne_atrybuty[0]\n",
    "    atrybut_2 = aktualne_atrybuty[1]\n",
    "\n",
    "    atrybut_1_index = dane.columns.get_loc(atrybut_1) - 1\n",
    "    atrybut_2_index = dane.columns.get_loc(atrybut_2) - 1\n",
    "\n",
    "    # zdefiniowanie modelu klasyfikatora\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # weryfikacja\n",
    "    weryfikuj(model,dane_podzielone,[atrybut_1_index,atrybut_2_index])\n",
    "\n",
    "    granice(model, dane_podzielone, atrybut_1_index, atrybut_2_index, \"n_neighbours dla x = \" + atrybut_1 + \", y = \" + atrybut_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
